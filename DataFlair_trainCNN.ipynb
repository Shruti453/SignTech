{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37fb5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "# from keras.optimizers import Adam, SGD\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffba616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3010 images belonging to 10 classes.\n",
      "Found 410 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_path = r'D:\\Desktop\\ML\\sign_language\\gesture\\contours\\train'\n",
    "test_path = r'D:\\Desktop\\ML\\sign_language\\gesture\\contours\\test'\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), classes =['1','2','3','4','5','6','7','8','9','10'],  class_mode='categorical', batch_size=10,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), classes = ['1','2','3','4','5','6','7','8','9','10'], class_mode='categorical', batch_size=10, shuffle=True)\n",
    "\n",
    "imgs, labels = next(train_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8472bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACGgAAADaCAYAAADw3eaaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQrklEQVR4nO3d0Y7bNhAF0HXh//9l9yFIV6vaXlnSFcnhOU8FmibagCOS6uDO7fF4fAEAAAAAAAAAkPNP6wcAAAAAAAAAAKhOgwYAAAAAAAAAQJgGDQAAAAAAAACAMA0aAAAAAAAAAABhGjQAAAAAAAAAAMI0aAAAAAAAAAAAhN3f/cvb7fa46kGggsfjcdvy69QWfEZtQYbaggy1BRlqCzLUFmSoLchQW5CxpbbUFXzmVV1J0AAAAAAAAAAACNOgAQAAAAAAAAAQpkEDAAAAAAAAACBMgwYAAAAAAAAAQNi99QMAAAAAAAC09Hg8/vvn2+3W8EkAgMokaAAAAAAAAAAAhGnQAAAAAAAAAAAI06ABAAAAAAAAABB2b/0AAAAAAAAzejweL//d7Xa78ElgHu/q7tWvUY8AwFkkaAAAAAAAAAAAhGnQAAAAAAAAAAAIM+IEAAAAAODr51iD1EiDLeMVrnoWYBv1CACcRYIGAAAAAAAAAECYBg0AAAAAAAAAgDAjTgAAoAOvoq7F5wIA5LwbN+J8BudRTwAAf0jQAAAAAAAAAAAI06ABAAAAAAAAABBmxAkA8BGxpHCOd3Har36dOoO2ttatWgUAZtfbfWfr8wD7bakzdyUACRoAAAAAAAAAAHEaNAAAAAAAAAAAwow4AQDe6i2WFACuJA4bgB4cvW+928/c3+B36gSec18C+JwEDQAAAAAAAACAMA0aAAAAAAAAAABhGjQAAAAAAAAAAMLurR8AAADY5ujscZjBuxnI6gaAM1Q7k1X7eaBH786or6hHjni15qwrgPYkaAAAAAAAAAAAhGnQAAAAAAAAAAAIM+IEmI54N6raGpdprcPvttSTWoJ+bN0DRbgDAABVbbkXrX/Np/eiPeN6APhJggYAAAAAAAAAQJgGDQAAAAAAAACAMCNOgClcEe8GLYgVhPN8Wk/2DWgrtQfaWwGowp7GaKqNo1ODAMAzEjQAAAAAAAAAAMI0aAAAAAAAAAAAhBlx0sC7aLMK0W0A9G1LZKgYTpjbnneAcywAMKL1GcZdCAAASJKgAQAAAAAAAAAQpkEDAAAAAAAAACDMiJOLbI1H3BI7D1xDPUI/tuyj6hSAil7tgfY9qjJmCwCglqNntXfnQ+dAEtzDSZOgAQAAAAAAAAAQpkEDAAAAAAAAACBMgwYAAAAAAAAAQNi99QPw2nLGkblGAMxkz+xx+yZHLdfNnjU4uhl/ZuYzyv6wpR7te1RydA9SDwD9Wb+P3Td+Zw+Db94ZXGnrenPv4CwSNAAAAAAAAAAAwjRoAAAAAAAAAACEGXECAAAADYnvBRjX+h0u7hrO0VttbYm1d6aDY9QQ9G1Pjbbev3slQQMAAAAAAAAAIEyDBgAAAAAAAABAmBEnF1lGuIhpAgCoZ0vkLQDwh28jzOaqNa+2ADibvQX+z3dAjpCgAQAAAAAAAAAQpkEDAAAAAAAAACDMiBNgCsYMQX2i5JjNej9TA1xt65nK2szw9wrf1ANH+EaghgAAeM5ZOUOCBgAAAAAAAABAmAYNAAAAAAAAAIAwI04A4IAtEV/iYoFn1u8GkYGMYPR1unz+1vvz6H+XAABX6ukcB1u8Ou9bvz/tuRf5OwRGJ0EDAAAAAAAAACBMgwYAAAAAAAAAQJgGDQAAAAAAAACAsHvrB2AbM/agLTUIeXtmTkLK8l2/Z23aNwAAuIJ7FKM4eseCKtbr3zcDgPlI0AAAAAAAAAAACNOgAQAAAAAAAAAQZsRJA+vIKpFuALXNGF1ovANnenVWsrZgDCPsCe5kkKfO6JXvdMARR98ZvZ6PmccI9zXgWva2PAkaAAAAAAAAAABhGjQAAAAAAAAAAMKMOBnQjFH50BOxb9APNTg3Z6Kf9uxPIrz51HJttVg/s6/Z2d9zsKQemI01D998m4OxzH6Po39HR975RsmnJGgAAAAAAAAAAIRp0AAAAAAAAAAACDPiBAAuJooTMnqtrV6fC1qYvR5E+wLUd8W7/uifMeMeTF9aj82Dnsx+RwL6MMJ+/O4ZR3t/StAAAAAAAAAAAAjToAEAAAAAAAAAEGbECQAcMHosZ+sYxRH/zhhD67UNAABAnrsf1Ke2YV5b///BaOcBCRoAAAAAAAAAAGEaNAAAAAAAAAAAwjRoAAAAAAAAAACE3Vs/AAAAvLOcG7h17iAAAFTiHAz9UI+kLNfW8lvILH8+VDFjLZ35c86wz0rQAAAAAAAAAAAI06ABAAAAAAAAABBmxAkANDRj3BlcTZ1BxtHxQ3tq88yRRzNEZgIAzGSUu1/Pz8Z5WtyXzuS+BLVVq/HR9lYJGgAAAAAAAAAAYRo0AAAAAAAAAADCjDgpoHXUFYzmzGhsWBo96h1G0GLNp0YqVDi3VfgZIM3+DEAPnNuYjTMYlVT7lgC96/Wb+55nGeWd0dPf8xUkaAAAAAAAAAAAhGnQAAAAAAAAAAAIM+IEADrUIrpwthgx5jR7LKg6p1ez1yZUZd8B4De9xsjDma5a5+oJ+uN7x3Ozv6MkaAAAAAAAAAAAhGnQAAAAAAAAAAAIM+IE4IB1DJOIKvjd7PFl9GPPO/zMuNBkLYhP5GqidH/ydwAAACT4Hg1z8X3hudHffRI0AAAAAAAAAADCNGgAAAAAAAAAAIRp0AAAAAAAAAAACLu3fgBys8xHn78DMLLUu339e8PM1rXgHAU12Pd+mv3nh1f27Pvqidm8WvPv6kedAAB8O/M7/1apP+fM33fPmfHon1/pnCpBAwAAAAAAAAAgTIMGAAAAAAAAAECYEScAQNTZkWyVosw4l7Fxz10Vvwh/nT1+COjTiLVdaX+HLfbUqfFBAFnJca2V2FuoqMV9pPU7ovWf3ysJGgAAAAAAAAAAYRo0AAAAAAAAAADCjDgByhKdRC+S0YXi/qAdYxzgGvY9uJb9DPiUvRoAYL9qd7Azf56qZ0sJGgAAAAAAAAAAYRo0AAAAAAAAAADCjDgJqhZJA71Tc8zIuofnlvF3xgpBHfY9yFBbAABtnPn9AhjHiPV+1XfRGb6/StAAAAAAAAAAAAjToAEAAAAAAAAAEGbESWHiuOF66o4tRBfCtVLjToBt7HvQJ/UInMX3D/iM74cAVON++RkJGgAAAAAAAAAAYRo0AAAAAAAAAADCNGgAAAAAAAAAAITdWz9ABebqQIbaAoC+mI8M11BrAABzWH7/dAZkuQZ8Gwd6dvY7arY9UIIGAAAAAAAAAECYBg0AAAAAAAAAgDAjTt4QIQXXUnMApIkLBYA/Zt8TRcrDfmoGMtb7sVpjNtY8vXOHOu9nnr3eJWgAAAAAAAAAAIRp0AAAAAAAAAAACDPiZGXGSBpoSc0xu9lj0baaPfIMoAr7HgCMyZ0MAADOIUEDAAAAAAAAACBMgwYAAAAAAAAAQJgRJ1+ideEK6gyA3qxjmu1VADCn5RnAGAcAoAfGQwLVuGt9k6ABAAAAAAAAABCmQQMAAAAAAAAAIEyDBgAAAAAAAABA2L31A1zFjC64nroDAIC2tpzJzYEFAAAAuIYEDQAAAAAAAACAMA0aAAAAAAAAAABhpUecGK8AAABjOHp2N6KBmR2tn/V/r54A+PqyHwAAcIzz5HMSNAAAAAAAAAAAwjRoAAAAAAAAAACElR5xAlzLWCFgNHveW2LZYD9nBTjPmfVkbwPgL3sCAABkSdAAAAAAAAAAAAjToAEAAAAAAAAAEGbEySTW8bfiCgGYibEKUJMz7Xi8j5/bupaNNQEgwZ4AQCv2IEa1XLu+dfApCRoAAAAAAAAAAGEaNAAAAAAAAAAAwow4mYSYKABmcnasnH0U9jOSAfqhhgAAAADakqABAAAAAAAAABCmQQMAAAAAAAAAIEyDBgAAAAAAAABA2L31AwAAnOHxeJz2e91ut9N+L5iReoTPrGtmue6P1pMaYosz1xzQP3sDAAC0I0EDAAAAAAAAACBMgwYAAAAAAAAAQFi5ESeiOAGAPcT8Qj/UI7Nzr6Ul404AANpzDgOoS4IGAAAAAAAAAECYBg0AAAAAAAAAgLByI05EcQJAPak93RgF+EzyfK0e4TzqiSN8SwGANpzhAMbh3sQREjQAAAAAAAAAAMI0aAAAAAAAAAAAhJUbcQK0s47hE/EE9EhkKADV2NsAgAqMLwcAZiBBAwAAAAAAAAAgTIMGAAAAAAAAAECYEScAAEATxjLAfuqHFPHyAACkuMcASNAAAAAAAAAAAIjToAEAAAAAAAAAEKZBAwAAAAAAAAAg7N76AQAA0sy3hD6oRQAAAABgZhI0AAAAAAAAAADCNGgAAAAAAAAAAIQZcQJwItHt0Ae1CEBF9jeutlxzj8ej4ZMAMJv1ucc+BABUIUEDAAAAAAAAACBMgwYAAAAAAAAAQJgRJ0CMOFwAwEgGnAMBoD1nMgCA8/j/XxwhQQMAAAAAAAAAIEyDBgAAAAAAAABAWOkRJ7PHy4guBAAAWpv9XnaUex3Atexb0Ce1yWyseWBUvmP8ToIGAAAAAAAAAECYBg0AAAAAAAAAgLDSI04ArraMmxPjBNdSc9AP9QgAAKQY/QAAjEyCBgAAAAAAAABAmAYNAAAAAAAAAIAwDRoAAAAAAAAAAGH31g9wFXPpoC01CCQs3y1AW+oR9lM/jGC9Tqve65Y/l9oE4ErrvdU+BDCGWe5KnEeCBgAAAAAAAABAmAYNAAAAAAAAAICwaUacAAA1iPiEdtQfHKOGqMQYSwB6YD8CAEYjQQMAAAAAAAAAIEyDBgAAAAAAAABA2JQjTtaxslWjz5Y/lyhdeiJ6EJ5TG9/sW9AP9QjHqCFmsGWdj3i+XT+zep5PpTua74QwHnXLX5X2I5iBmuU3EjQAAAAAAAAAAMI0aAAAAAAAAAAAhE054gQA6I+4TlqbPX5QDcJ+6gd+N8u4WQDamf1OBwCMQYIGAAAAAAAAAECYBg0AAAAAAAAAgDAjTr5En0FL6g/mJhIe2lKDXM3ZD/jL+wCAJKO1qMrahrG49/CMBA0AAAAAAAAAgDANGgAAAAAAAAAAYRo0AAAAAAAAAADC7q0fAKCq5Tyx9WxA+E3l2XTqAdpRfwCwnzseVazvmNYz9M8eBMAo7Fm/k6ABAAAAAAAAABCmQQMAAAAAAAAAIMyIE6Ab66ijamMdAAAA+L/K4/2oo/I6FUMNMK7K+xNUo175S4IGAAAAAAAAAECYBg0AAAAAAAAAgDAjTlbEywAAAADwjpEQAGOp9N3fHsTI1vVnDTOrSvsSn5OgAQAAAAAAAAAQpkEDAAAAAAAAACDMiBOAC4geBAAA+J2oX0ZQeZ36fgEwrsr7E1S2PnNVql9ny+ckaAAAAAAAAAAAhGnQAAAAAAAAAAAIM+JkEus4HDEyAAAAAMeJ7aUqa5uqKo2BUKeMzhoGZiRBAwAAAAAAAAAgTIMGAAAAAAAAAECYBg0AAAAAAAAAgLB76wcAeKXSPEg4Yj1/UT1Anj0IAIAt3NcAAIBPSNAAAAAAAAAAAAjToAEAAAAAAAAAEGbECQAAAADdGXF0xPIZ188PI7O2qarSeMv186tVRmOvgT8q7U1LavybBA0AAAAAAAAAgDANGgAAAAAAAAAAYbdK0SgAAAAAAAAAAD2SoAEAAAAAAAAAEKZBAwAAAAAAAAAgTIMGAAAAAAAAAECYBg0AAAAAAAAAgDANGgAAAAAAAAAAYRo0AAAAAAAAAADC/gXZB90QID2iLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Plotting the images...\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(30,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotImages(imgs)\n",
    "print(imgs.shape)\n",
    "print(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7693b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(64,activation =\"relu\"),\n",
    "    Dense(128,activation =\"relu\"),\n",
    "    Dense(128,activation =\"relu\"),\n",
    "    Dense(10,activation =\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babbd198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "301/301 [==============================] - 30s 98ms/step - loss: 0.7331 - accuracy: 0.8934 - val_loss: 1.0288 - val_accuracy: 0.8610 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "301/301 [==============================] - 18s 58ms/step - loss: 0.0670 - accuracy: 0.9817 - val_loss: 2.4595 - val_accuracy: 0.7756 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "301/301 [==============================] - 19s 63ms/step - loss: 0.0190 - accuracy: 0.9960 - val_loss: 1.3214 - val_accuracy: 0.8098 - lr: 2.0000e-04\n",
      "loss of 1.1002273559570312; accuracy of 60.00000238418579%\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "# model.compile(optimizer=gradient_descent_v2.SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=10, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n",
    "imgs, labels = next(train_batches) # For getting next batch of imgs...\n",
    "\n",
    "imgs, labels = next(test_batches) # For getting next batch of imgs...\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964b773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.7330610156059265, 0.06701863557100296, 0.019035520032048225], 'accuracy': [0.8933554887771606, 0.9817276000976562, 0.9960132837295532], 'val_loss': [1.0288382768630981, 2.4595224857330322, 1.3214125633239746], 'val_accuracy': [0.8609756231307983, 0.7756097316741943, 0.8097561001777649], 'lr': [0.001, 0.001, 0.00020000001]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('best_model_dataflair.h5')\n",
    "# model.save('best_model_dataflair_grayedges.h5')\n",
    "\n",
    "print(history2.history)\n",
    "\n",
    "imgs, labels = next(test_batches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973d8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 13.355707168579102; accuracy of 10.000000149011612%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(r\"best_model_dataflair3.h5\")\n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "scores #[loss, accuracy] on test data...\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efdb3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions on a small set of test data--\n",
      "\n",
      "8            6            6            1            4            9            3            10            4            6            "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels\n",
      "9\n",
      "7\n",
      "3\n",
      "1\n",
      "6\n",
      "10\n",
      "10\n",
      "2\n",
      "5\n",
      "7\n",
      "(10, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7330610156059265, 0.06701863557100296, 0.019035520032048225],\n",
       " 'accuracy': [0.8933554887771606, 0.9817276000976562, 0.9960132837295532],\n",
       " 'val_loss': [1.0288382768630981, 2.4595224857330322, 1.3214125633239746],\n",
       " 'val_accuracy': [0.8609756231307983, 0.7756097316741943, 0.8097561001777649],\n",
       " 'lr': [0.001, 0.001, 0.00020000001]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {'1':'One','2':'Two','3':'Three','4':'Four','5':'Five','6':'Six','7':'Seven','8':'Eight','9':'Nine', '10':'Ten'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions on a small set of test data--\")\n",
    "\n",
    "print(\"\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(np.argmax(i)+1, end=\"            \")\n",
    "#     print(word_dict[str(np.argmax(i))], end='   ')\n",
    "\n",
    "plotImages(imgs)\n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "#     print(word_dict[np.argmax(i)], end='   ')\n",
    "    print(np.argmax(i)+1)\n",
    "\n",
    "print(imgs.shape)\n",
    "\n",
    "history2.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
